import fitz  # PyMuPDF
import cv2
import numpy as np
import os
import base64
import tempfile
import streamlit as st
import gdown
import re
import cloudscraper
import json
import urllib.parse
import datetime
import requests 
from bs4 import BeautifulSoup

# --- ×”×’×“×¨×•×ª ××¢×¨×›×ª ---
DEFAULT_START_ID = 72680
AUTO_CUT_PDF = "auto_cut_document.pdf"

# --- ×¤×•× ×§×¦×™×•×ª ××¡×“ × ×ª×•× ×™× ×•×–××Ÿ ---

@st.cache_data(ttl=600) 
def get_config():
    """×©×•×œ×£ ××ª ×”× ×ª×•× ×™× ×××¡×“ ×”× ×ª×•× ×™× ×‘×¢× ×Ÿ (JSONBin)"""
    try:
        if 'JSONBIN_BIN_ID' in st.secrets and 'JSONBIN_API_KEY' in st.secrets:
            url = f"https://api.jsonbin.io/v3/b/{st.secrets['JSONBIN_BIN_ID']}"
            headers = {'X-Master-Key': st.secrets['JSONBIN_API_KEY']}
            req = requests.get(url, headers=headers)
            if req.status_code == 200:
                return req.json().get('record', {})
    except Exception as e:
        st.warning(f"×©×’×™××” ×‘×§×¨×™××” ×××¡×“ ×”× ×ª×•× ×™×: {e}")
    return {}

def save_config(data):
    """×©×•××¨ ××ª ×”× ×ª×•× ×™× ×œ××¡×“ ×”× ×ª×•× ×™× ×‘×¢× ×Ÿ ×•×× ×§×” ××ª ×–×™×›×¨×•×Ÿ ×”××˜××•×Ÿ"""
    try:
        if 'JSONBIN_BIN_ID' in st.secrets and 'JSONBIN_API_KEY' in st.secrets:
            url = f"https://api.jsonbin.io/v3/b/{st.secrets['JSONBIN_BIN_ID']}"
            headers = {
                'Content-Type': 'application/json',
                'X-Master-Key': st.secrets['JSONBIN_API_KEY']
            }
            requests.put(url, json=data, headers=headers)
            get_config.clear() 
    except Exception as e:
        st.error(f"×©×’×™××” ×‘×©××™×¨×” ×œ××¡×“ ×”× ×ª×•× ×™×: {e}")

def get_next_saturday_1600(from_date):
    """××—×©×‘ ××ª×™ ×ª×—×•×œ ×”×©×‘×ª ×”×§×¨×•×‘×” ×‘×©×¢×” 16:00"""
    days_ahead = 5 - from_date.weekday()
    if days_ahead < 0 or (days_ahead == 0 and from_date.hour >= 16):
        days_ahead += 7
    next_sat = from_date + datetime.timedelta(days=days_ahead)
    return next_sat.replace(hour=16, minute=0, second=0, microsecond=0)

# --- ×¤×•× ×§×¦×™×™×ª ×”××•×˜×•××¦×™×” ×”××¨×›×–×™×ª ---

def prepare_auto_pdf():
    """
    ×× ×”×œ ××ª ×”×œ×•×’×™×§×” ×”××•×˜×•××˜×™×ª.
    ××—×–×™×¨: (×”×¦×œ×—×”?, ×”×•×“×¢×ª_×©×’×™××”, ×©×_×”×§×•×‘×¥)
    """
    config = get_config()
    last_post_id = config.get("last_post_id", DEFAULT_START_ID)
    last_drive_id = config.get("last_drive_id", None)
    last_check_str = config.get("last_check_time")
    last_title = config.get("last_title", "×’×™×œ×™×•×Ÿ ××©×›×Ÿ ×©×™×œ×”") # ×˜×¢×™× ×ª ×”×©× ××”×¢× ×Ÿ

    now = datetime.datetime.now()
    should_scrape = False

    if not last_check_str:
        should_scrape = True
    else:
        last_check = datetime.datetime.fromisoformat(last_check_str)
        next_check = get_next_saturday_1600(last_check)
        if now >= next_check:
            should_scrape = True

    target_post_id = last_post_id
    target_drive_id = last_drive_id
    target_title = last_title
    found_new = False

    scraper = cloudscraper.create_scraper(browser={'browser': 'chrome', 'platform': 'windows', 'desktop': True})
    
    if should_scrape:
        cat_url = "https://kav.meorot.net/category/%d7%a2%d7%9c%d7%95%d7%a0%d7%99-%d7%a9%d7%91%d7%aa/%d7%9e%d7%a9%d7%9b%d7%9f-%d7%a9%d7%99%d7%9c%d7%94/"
        cat_res = scraper.get(cat_url)
        
        if cat_res.status_code == 200:
            soup = BeautifulSoup(cat_res.text, "html.parser")
            post_link = soup.select_one("h3 a, h2 a")
            
            if post_link:
                url = post_link["href"]
                
                id_match = re.search(r'kav\.meorot\.net/(\d+)', url)
                if id_match:
                    scraped_post_id = int(id_match.group(1))
                    
                    if scraped_post_id > last_post_id:
                        post_res = scraper.get(url)
                        if post_res.status_code == 200:
                            post_soup = BeautifulSoup(post_res.text, "html.parser")
                            h1_tag = post_soup.select_one("h1")
                            full_title = h1_tag.get_text(strip=True) if h1_tag else post_link.get_text(strip=True)
                            
                            drive_patterns = [
                                r'https://drive\.google\.com/file/d/([a-zA-Z0-9_-]+)', 
                                r'https%3A%2F%2Fdrive\.google\.com%2Ffile%2Fd%2F([a-zA-Z0-9_-]+)'
                            ]
                            for pattern in drive_patterns:
                                match = re.search(pattern, post_res.text)
                                if match:
                                    target_drive_id = match.group(1)
                                    target_post_id = scraped_post_id
                                    target_title = full_title
                                    found_new = True
                                    break

    # ×× ×”×§×•×‘×¥ ×§×™×™× ×•××™×Ÿ ×—×“×© - ××—×–×™×¨×™× ××•×ª×• ×™×—×“ ×¢× ×”×©× ×”×©××•×¨ ×©×œ×• ××”×“×¨×™×™×‘
    if not found_new and os.path.exists(AUTO_CUT_PDF):
        return True, None, target_title

    if not target_drive_id:
        post_res = scraper.get(f"https://kav.meorot.net/{target_post_id}/")
        if post_res.status_code == 200:
            drive_patterns = [r'https://drive\.google\.com/file/d/([a-zA-Z0-9_-]+)', r'https%3A%2F%2Fdrive\.google\.com%2Ffile%2Fd%2F([a-zA-Z0-9_-]+)']
            for pattern in drive_patterns:
                match = re.search(pattern, post_res.text)
                if match:
                    target_drive_id = match.group(1)
                    break
                    
    if not target_drive_id:
        return False, "×œ× ×”×¦×œ×—× ×• ×œ××ª×¨ ×§×™×©×•×¨ ×ª×§×™×Ÿ ×œ×’×•×’×œ ×“×¨×™×™×‘ ×‘×¤×•×¡×˜.", None

    downloaded_path = gdown.download(id=target_drive_id, quiet=False)
    
    if not downloaded_path:
        return False, "×©×’×™××” ×‘×”×•×¨×“×ª ×”×§×•×‘×¥ ××’×•×’×œ ×“×¨×™×™×‘.", None

    original_filename = os.path.basename(downloaded_path)

    if os.path.getsize(downloaded_path) < 100000:
        os.remove(downloaded_path)
        return False, "×”×§×•×‘×¥ ×©×”×•×¨×“ ×§×˜×Ÿ ××“×™! × ×¨××” ×©×’×•×’×œ ×“×¨×™×™×‘ ×—×¡× ××ª ×”×”×•×¨×“×”.", None

    START_IMG, END_IMG = "start.png", "end.png"
    if not os.path.exists(START_IMG) or not os.path.exists(END_IMG):
        os.remove(downloaded_path)
        return False, "×©×’×™××”: ×§×‘×¦×™ ×ª××•× ×•×ª ×”×—×™×ª×•×š ×—×¡×¨×™× ×‘×©×¨×ª.", None

    with open(START_IMG, "rb") as f: start_b64 = base64.b64encode(f.read())
    with open(END_IMG, "rb") as f: end_b64 = base64.b64encode(f.read())

    # ×—×™×ª×•×š ×”×§×•×‘×¥ ××ª×•×š ×”×§×•×‘×¥ ×”××§×•×¨×™ ×©×™×¨×“
    success = extract_pdf_by_images(downloaded_path, AUTO_CUT_PDF, start_b64, end_b64)
    os.remove(downloaded_path) # × ×™×§×•×™ ×”×§×•×‘×¥ ×”××§×•×¨×™

    if success:
        if found_new:
            save_config({
                "last_post_id": target_post_id,
                "last_drive_id": target_drive_id,
                "last_check_time": now.isoformat(),
                "last_title": original_filename
            })
        return True, None, original_filename
    else:
        return False, "×œ× ×”×¦×œ×—× ×• ×œ××¦×•× ××ª ×¡×™×× ×™ ×”×”×ª×—×œ×” ×•×”×¡×™×•× ×‘×ª×•×š ×”-PDF ×”×—×“×©.", None

# --- ×¤×•× ×§×¦×™×•×ª ×œ×•×’×™×§×ª ×”×—×™×ª×•×š ---

def find_image_in_page(page_pixmap, template_b64, threshold=0.7):
    img_array = np.frombuffer(page_pixmap.samples, dtype=np.uint8).reshape(page_pixmap.h, page_pixmap.w, page_pixmap.n)
    if page_pixmap.n >= 3:
        img_array = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)
    img_data = base64.b64decode(template_b64)
    np_arr_template = np.frombuffer(img_data, np.uint8)
    template = cv2.imdecode(np_arr_template, cv2.IMREAD_GRAYSCALE)
    if template is None: return False
    for scale in np.linspace(0.4, 1.6, 12):
        width = int(template.shape[1] * scale)
        height = int(template.shape[0] * scale)
        if height == 0 or width == 0 or height > img_array.shape[0] or width > img_array.shape[1]: continue
        resized_template = cv2.resize(template, (width, height), interpolation=cv2.INTER_AREA)
        result = cv2.matchTemplate(img_array, resized_template, cv2.TM_CCOEFF_NORMED)
        _, max_val, _, _ = cv2.minMaxLoc(result)
        if max_val >= threshold: return True
    return False

def extract_pdf_by_images(input_pdf_path, output_pdf_path, start_image_b64, end_image_b64):
    doc = fitz.open(input_pdf_path)
    start_page = -1
    end_page = -1
    for page_num in range(len(doc)):
        page = doc.load_page(page_num)
        pix = page.get_pixmap(matrix=fitz.Matrix(1.2, 1.2))
        if start_page == -1:
            if find_image_in_page(pix, start_image_b64): start_page = page_num
        if start_page != -1 and end_page == -1:
            if find_image_in_page(pix, end_image_b64):
                end_page = page_num
                break
    if start_page != -1 and end_page != -1:
        new_doc = fitz.open()
        new_doc.insert_pdf(doc, from_page=start_page, to_page=end_page)
        new_doc.save(output_pdf_path)
        new_doc.close()
        doc.close()
        return True
    doc.close()
    return False

# --- ×××©×§ ××©×ª××© ---

def main():
    st.set_page_config(page_title="×”×•×¨×“×ª ×¡×™×›×•× ×¤×¨×©×” - ××©×›×Ÿ ×©×™×œ×”", page_icon="ğŸ“„")
    st.markdown("<style>.block-container { direction: rtl; text-align: right; }</style>", unsafe_allow_html=True)
    
    title_placeholder = st.empty()
    title_placeholder.title("×”×•×¨×“×ª ×¡×™×›×•× ×”×¤×¨×©×” ×”×§×¨×•×‘×” ××’×™×œ×™×•×Ÿ ××©×›×Ÿ ×©×™×œ×”")
    
    upload_option = st.radio("××™×š ×ª×¨×¦×” ×œ×˜×¢×•×Ÿ ××ª ×”-PDF?", 
                             ("×©×œ×™×¤×” ××•×˜×•××˜×™×ª (××©×›×Ÿ ×©×™×œ×”)", 
                              "×”×¢×œ××ª ×§×•×‘×¥ ××”××—×©×‘", 
                              "×§×™×©×•×¨ ×-Google Drive"))
    
    START_IMG, END_IMG = "start.png", "end.png"

    if upload_option == "×©×œ×™×¤×” ××•×˜×•××˜×™×ª (××©×›×Ÿ ×©×™×œ×”)":
        with st.spinner("××•×•×“× ×•××›×™×Ÿ ××ª ×”×’×™×œ×™×•×Ÿ ×”×¢×“×›× ×™ ×‘×™×•×ª×¨..."):
            success, error_msg, target_title = prepare_auto_pdf()
        
        if success and os.path.exists(AUTO_CUT_PDF):
            st.success("âœ… ×”×§×•×‘×¥ ××•×›×Ÿ ×¢×‘×•×¨×š!")
            
            # ×”×¦×’×ª ×”×©× ×‘×›×•×ª×¨×ª (×œ×œ× ×¡×™×•××ª ×”-.pdf ×›×“×™ ×©×™×™×¨××” ××¡×ª×˜×™)
            display_title = target_title.replace(".pdf", "")
            title_placeholder.title(f"×”×•×¨×“×ª ×¡×™×›×•× ×”×¤×¨×©×” ×”×§×¨×•×‘×”: {display_title}")
            
            # --- ×”×ª×™×§×•×Ÿ ×”×§×¨×™×˜×™: ××›×™×¤×ª ×¡×™×•××ª .pdf ×•× ×™×§×•×™ ×ª×•×•×™× ×—×•×§×™ ---
            safe_filename = re.sub(r'[\\/*?:"<>|]', "", target_title).strip()
            if not safe_filename.lower().endswith('.pdf'):
                safe_filename += ".pdf"
            
            with open(AUTO_CUT_PDF, "rb") as f:
                st.download_button(
                    label=f"ğŸ“¥ ×”×•×¨×“ ××ª ×”×§×•×‘×¥: {safe_filename}", 
                    data=f, 
                    file_name=safe_filename, 
                    mime="application/pdf"
                )
        else:
            st.error(error_msg)

    else:
        uploaded_file = None
        manual_link = ""
        
        if upload_option == "×”×¢×œ××ª ×§×•×‘×¥ ××”××—×©×‘":
            uploaded_file = st.file_uploader("×‘×—×¨ ×§×•×‘×¥ PDF ××”××—×©×‘", type=["pdf"], key="manual_upload")
        elif upload_option == "×§×™×©×•×¨ ×-Google Drive":
            manual_link = st.text_input("×”×“×‘×§ ×›××Ÿ ×§×™×©×•×¨ ×©×™×ª×•×£ ×œ-PDF ×-Google Drive:")
            
        if st.button("×”×¤×¢×œ ×—×™×ª×•×š ×™×“× ×™"):
            if not os.path.exists(START_IMG) or not os.path.exists(END_IMG):
                st.error("×©×’×™××”: ×§×‘×¦×™ ×”×ª××•× ×•×ª (start.png / end.png) ×—×¡×¨×™×.")
                return

            with st.spinner("××‘×¦×¢ ××©×™×›×” ×•×—×™×ª×•×š..."):
                try:
                    with open(START_IMG, "rb") as f: start_b64 = base64.b64encode(f.read())
                    with open(END_IMG, "rb") as f: end_b64 = base64.b64encode(f.read())

                    input_path = ""
                    
                    if upload_option == "×”×¢×œ××ª ×§×•×‘×¥ ××”××—×©×‘":
                        if not uploaded_file:
                            st.warning("× × ×œ×”×¢×œ×•×ª ×§×•×‘×¥.")
                            return
                        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
                            tmp.write(uploaded_file.getvalue())
                            input_path = tmp.name
                        
                        output_path = input_path.replace(".pdf", "_fixed.pdf")
                        if extract_pdf_by_images(input_path, output_path, start_b64, end_b64):
                            st.success("×”×—×™×ª×•×š ×‘×•×¦×¢ ×‘×”×¦×œ×—×”!")
                            
                            safe_manual_name = uploaded_file.name
                            if not safe_manual_name.lower().endswith('.pdf'):
                                safe_manual_name += ".pdf"
                            safe_manual_name = safe_manual_name.replace(".pdf", "_fixed.pdf")
                                
                            with open(output_path, "rb") as f:
                                st.download_button("ğŸ“¥ ×”×•×¨×“ ×§×•×‘×¥ ×—×ª×•×š", f, safe_manual_name, "application/pdf")
                        else:
                            st.error("×œ× ×”×¦×œ×—× ×• ×œ××¦×•× ××ª ×¡×™×× ×™ ×”×”×ª×—×œ×” ×•×”×¡×™×•× ×‘×ª×•×š ×”×§×•×‘×¥.")
                    
                    elif upload_option == "×§×™×©×•×¨ ×-Google Drive":
                        if not manual_link:
                            st.warning("× × ×œ×”×–×™×Ÿ ×œ×™× ×§.")
                            return
                        
                        file_id = None
                        id_match = re.search(r'/d/([a-zA-Z0-9_-]+)', manual_link)
                        if id_match:
                            file_id = id_match.group(1)
                        else:
                            st.warning("×”×§×™×©×•×¨ ×œ× ×ª×§×™×Ÿ ××• ×œ× ××›×™×œ ××–×”×” (ID).")
                            return
                            
                        downloaded_path = gdown.download(id=file_id, quiet=False)
                        if downloaded_path:
                            original_filename = os.path.basename(downloaded_path)
                            
                            # ×”×‘×˜×—×ª ×¡×™×•××ª ×—×•×§×™×ª ×’× ×‘×”×•×¨×“×” ×™×“× ×™×ª ××§×™×©×•×¨
                            safe_manual_name = re.sub(r'[\\/*?:"<>|]', "", original_filename).strip()
                            if safe_manual_name.lower().endswith('.pdf'):
                                safe_manual_name = safe_manual_name.replace(".pdf", "_fixed.pdf")
                            else:
                                safe_manual_name += "_fixed.pdf"
                                
                            output_path = "temp_fixed.pdf"
                            
                            if extract_pdf_by_images(downloaded_path, output_path, start_b64, end_b64):
                                st.success("×”×—×™×ª×•×š ×‘×•×¦×¢ ×‘×”×¦×œ×—×”!")
                                with open(output_path, "rb") as f:
                                    st.download_button(f"ğŸ“¥ ×”×•×¨×“ ××ª {safe_manual_name}", f, safe_manual_name, "application/pdf")
                            else:
                                st.error("×œ× ×”×¦×œ×—× ×• ×œ××¦×•× ××ª ×¡×™×× ×™ ×”×”×ª×—×œ×” ×•×”×¡×™×•× ×‘×ª×•×š ×”×§×•×‘×¥.")
                            os.remove(downloaded_path)
                        else:
                            st.error("×œ× ×”×¦×œ×—× ×• ×œ×”×•×¨×™×“ ××ª ×”×§×•×‘×¥ ××”×œ×™× ×§ ×©×¡×•×¤×§.")
                
                except Exception as e:
                    st.error(f"××™×¨×¢×” ×©×’×™××”: {e}")

if __name__ == "__main__":
    main()
